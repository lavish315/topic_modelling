{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lavish315/topic_modelling/blob/main/Topic_Modeling_on_News_Articles_Capstone_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOGC-qoyhJeX"
      },
      "source": [
        "# <b><u> Project Title : Extraction/identification of major topics & themes discussed in news articles. </u></b>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y06xIdG26kRF"
      },
      "source": [
        "## <b> Problem Description </b>\n",
        "\n",
        "### In this project your task is to identify major themes/topics across a collection of BBC news articles. You can use clustering algorithms such as Latent Dirichlet Allocation (LDA), Latent Semantic Analysis (LSA) etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlLxAtlziMbP"
      },
      "source": [
        "## <b> Data Description </b>\n",
        "\n",
        "### The dataset contains a set of news articles for each major segment consisting of business, entertainment, politics, sports and technology. You need to create an aggregate dataset of all the news articles and perform topic modeling on this dataset. Verify whether these topics correspond to the different tags available."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "81e6c728-92d6-46b6-848f-2124df59fc92",
        "_uuid": "ea84e7b744d0d5701e0019253aa9905718e55d72",
        "id": "Fn5otZjiuYjz"
      },
      "source": [
        "## <b><u> Exploratory Data Analysis </u></b>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dByMsuzT8Tnw"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "from tqdm import tqdm\n",
        "from collections import Counter\n",
        "import ast\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.mlab as mlab\n",
        "import seaborn as sb\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from textblob import TextBlob\n",
        "import scipy.stats as stats\n",
        "\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "import matplotlib\n",
        "import spacy\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olTcgIGd2czL",
        "outputId": "98c05c65-a95d-4114-ed43-ba08c003f545"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas._libs.lib import maybe_indices_to_slice\n",
        "import csv\n",
        "import glob\n",
        "\n",
        "vals = []\n",
        "main_dataframe = pd.DataFrame()\n",
        "final_df = pd.DataFrame()\n",
        "path = '/content/drive/MyDrive/AlmaBetter/Data/Unsupervised machine learning/business'\n",
        "\n",
        "files = glob.glob(path + '/*.txt')\n",
        "\n",
        "for i in files:\n",
        "  df1 = pd.read_csv(i, sep=\"/n\",on_bad_lines='skip',encoding= 'unicode_escape')\n",
        "  vals.append('business')\n",
        "  main_dataframe = pd.concat([main_dataframe, df1], axis = 1)\n",
        "\n",
        "path = '/content/drive/MyDrive/AlmaBetter/Data/Unsupervised machine learning/entertainment'\n",
        "\n",
        "files = glob.glob(path + '/*.txt')\n",
        "\n",
        "for i in files:\n",
        "  df1 = pd.read_csv(i, sep=\"/n\",on_bad_lines='skip',encoding= 'unicode_escape')\n",
        "  vals.append('entertainment')\n",
        "  main_dataframe = pd.concat([main_dataframe, df1], axis = 1)\n",
        "\n",
        "path = '/content/drive/MyDrive/AlmaBetter/Data/Unsupervised machine learning/politics'\n",
        "\n",
        "files = glob.glob(path + '/*.txt')\n",
        "\n",
        "for i in files:\n",
        "  df1 = pd.read_csv(i, sep=\"/n\",on_bad_lines='skip',encoding= 'unicode_escape')\n",
        "  vals.append('politics')\n",
        "  main_dataframe = pd.concat([main_dataframe, df1], axis = 1)\n",
        "\n",
        "path = '/content/drive/MyDrive/AlmaBetter/Data/Unsupervised machine learning/sport'\n",
        "\n",
        "files = glob.glob(path + '/*.txt')\n",
        "\n",
        "for i in files:\n",
        "  df1 = pd.read_csv(i, sep=\"/n\",on_bad_lines='skip',encoding= 'unicode_escape')\n",
        "  vals.append('sport')\n",
        "  main_dataframe = pd.concat([main_dataframe, df1], axis = 1)\n",
        "\n",
        "path = '/content/drive/MyDrive/AlmaBetter/Data/Unsupervised machine learning/tech'\n",
        "\n",
        "files = glob.glob(path + '/*.txt')\n",
        "\n",
        "for i in files:\n",
        "  df1 = pd.read_csv(i, sep=\"/n\",on_bad_lines='skip',encoding= 'unicode_escape')\n",
        "  vals.append('tech')\n",
        "  main_dataframe = pd.concat([main_dataframe, df1], axis = 1)\n",
        "main_dataframe_transposed = main_dataframe.T\n",
        "main_dataframe_copy = main_dataframe_transposed\n",
        "main_dataframe_copy = main_dataframe_copy.reset_index()\n",
        "\n",
        "final_df[0] = main_dataframe_copy['index'].values\n",
        "main_dataframe_copy = main_dataframe_copy.iloc[: , 1:]\n",
        "main_dataframe_copy['new'] = main_dataframe_copy.apply(lambda row: ' '.join(row.dropna().astype(str)), axis=1)\n",
        "final_df[1]= main_dataframe_copy['new'].values\n",
        "final_df[2]=vals"
      ],
      "metadata": {
        "id": "rVdfOOuY5Dty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_df=final_df.drop_duplicates()\n"
      ],
      "metadata": {
        "id": "gQMy9QPJvasr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_df[2].value_counts(normalize=True)*100"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nF-ukEz-vhMC",
        "outputId": "f33cf892-75ab-4f93-f29f-875c95285115"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "business         23.670588\n",
              "sport            23.670588\n",
              "politics         18.964706\n",
              "entertainment    17.364706\n",
              "tech             16.329412\n",
              "Name: 2, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_df[1] = final_df[1].astype('str') \n"
      ],
      "metadata": {
        "id": "BBLmRgqLvrya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing numbers\n",
        "def remove_numbers(text):\n",
        "\tnumber_pattern = r'\\d+'\n",
        "\twithout_number = re.sub(pattern=number_pattern, repl=\" \", string=text)\n",
        "\treturn without_number"
      ],
      "metadata": {
        "id": "yMIUkB58v3OR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "final_df[1]=final_df[1].apply(remove_numbers)\n"
      ],
      "metadata": {
        "id": "zANywTZGv4hb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}